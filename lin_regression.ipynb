{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import torch\n",
        "from torch.autograd import forward_ad\n",
        "from torch.nn.utils import parameters_to_vector\n",
        "\n",
        "\n",
        "def log_softmax(x):\n",
        "    return (x.exp()/x.exp().sum()).log()\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "  return x.exp()/x.exp().sum()\n",
        "\n",
        "\n",
        "def criterion(y, y_hat):\n",
        "    pred = log_softmax(y)\n",
        "    target = torch.nn.functional.one_hot(y_hat, num_classes=10)\n",
        "    return -torch.mul(target, pred).mean()\n",
        "\n",
        "def l2_loss(y, y_hat):\n",
        "    return torch.abs(y-y_hat).mean()\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "zjLaYbFOgZ4N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# FORWARD AD FUNCTIONS \n",
        "\n",
        "def preparation(model):\n",
        "    pointer = 0\n",
        "    indices = []\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad_(False)  # turn off grad for the original parameter node\n",
        "        num_param = p.numel()\n",
        "        index = torch.tensor(range(pointer, num_param + pointer))\n",
        "        indices.append(index)\n",
        "        pointer += num_param\n",
        "    return indices\n",
        "\n",
        "\n",
        "def forward_optim(model, criteria, x, y, indices, eta=2e-4):\n",
        "    \"\"\"\n",
        "    Function performing forward pass + SGD\n",
        "    \"\"\"\n",
        "    def f(params: torch.Tensor):\n",
        "        for p, index in zip(model.parameters(), indices):\n",
        "            p.mul_(0)\n",
        "            p.add_(params.index_select(0, index).view_as(p.data))\n",
        "        out = model(x)\n",
        "        loss = criteria(out, y)\n",
        "        return loss\n",
        "\n",
        "    v = [torch.normal(mean=0, std=1, size=p.shape)\n",
        "         for p in model.parameters()]\n",
        "\n",
        "    primal = parameters_to_vector(model.parameters())\n",
        "    tangent = parameters_to_vector(v)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with forward_ad.dual_level():\n",
        "            dual = forward_ad.make_dual(primal, tangent)\n",
        "            rst = f(dual)\n",
        "            my_loss, jvp = forward_ad.unpack_dual(rst)\n",
        "\n",
        "        # here SGD starts\n",
        "        i = 0\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                param.add_(-eta*jvp*tangent[i])\n",
        "                i += 1\n",
        "\n",
        "    return my_loss"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "A small test on linear regression"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "torch.manual_seed(111)\n",
        "\n",
        "class LinearRegressor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.regressor = torch.nn.Linear(\n",
        "            in_features=3, out_features=1, bias=False)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.regressor(X)\n",
        "\n",
        "# data creation for lin regression ------\n",
        "x1 = torch.arange(0, 10).float().unsqueeze(-1)\n",
        "x2 = torch.arange(0, 10).float().unsqueeze(-1)\n",
        "x3 = torch.arange(0, 10).float().unsqueeze(-1)\n",
        "X = torch.cat((x1, x2, x3), dim=1)\n",
        "eps = torch.normal(0, .03, (10, 3))\n",
        "X[:, (0, 1, 2)] += (eps)\n",
        "y = torch.arange(0, 10).float().unsqueeze(-1)\n",
        "# ------------------------------------------\n",
        "\n",
        "\n",
        "model = LinearRegressor()\n",
        "indeces = preparation(model)  # calling the preparation ALWAYS CALL AFTER definition of model\n",
        "\n",
        "# training\n",
        "for epoch in range(400):\n",
        "    my_loss = forward_optim(model, l2_loss, X, y, indeces, eta=2e-4)\n",
        "    if epoch % 20 == 19:\n",
        "        print(f\"Epoch [{epoch+1}] /  Loss : [{my_loss}]\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20] /  Loss : [3.374274492263794]\n",
            "Epoch [40] /  Loss : [3.0811939239501953]\n",
            "Epoch [60] /  Loss : [2.7915120124816895]\n",
            "Epoch [80] /  Loss : [2.6944334506988525]\n",
            "Epoch [100] /  Loss : [2.492323398590088]\n",
            "Epoch [120] /  Loss : [2.2233099937438965]\n",
            "Epoch [140] /  Loss : [1.8233766555786133]\n",
            "Epoch [160] /  Loss : [1.5074561834335327]\n",
            "Epoch [180] /  Loss : [1.3212858438491821]\n",
            "Epoch [200] /  Loss : [1.1421191692352295]\n",
            "Epoch [220] /  Loss : [0.8348051905632019]\n",
            "Epoch [240] /  Loss : [0.6050833463668823]\n",
            "Epoch [260] /  Loss : [0.30616238713264465]\n",
            "Epoch [280] /  Loss : [0.11028136312961578]\n",
            "Epoch [300] /  Loss : [0.02170298434793949]\n",
            "Epoch [320] /  Loss : [0.021589595824480057]\n",
            "Epoch [340] /  Loss : [0.02150806598365307]\n",
            "Epoch [360] /  Loss : [0.021565936505794525]\n",
            "Epoch [380] /  Loss : [0.02149207890033722]\n",
            "Epoch [400] /  Loss : [0.021580006927251816]\n"
          ]
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.9.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.0 64-bit"
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "colab": {
      "name": "try.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}