{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtyTP8_C79xR"
      },
      "source": [
        "# Training a MLP using backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opkZuz6b79xT"
      },
      "source": [
        "* **part 1** we train using `MLP`. \n",
        "* **part 2** we train using `Sequential` and `Linear`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t2PRtHa8IvXY"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax import numpy as jnp\n",
        "from jax import grad, jit\n",
        "from jax_forward import ReLU, LogSoftmax, MLP, Module, Sequential, Linear\n",
        "\n",
        "jax.config.update('jax_platform_name', 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6x8RCyW79xU"
      },
      "source": [
        "## Part 1\n",
        "We first define useful parameters that we are going to use later. Note that our model is a MLP imported from `net.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fuLi5I2ViLr9"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "layer_sizes = [784, 512, 256, 10]\n",
        "step_size = 0.01\n",
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "n_targets = 10\n",
        "key = jax.random.PRNGKey(0)\n",
        "function = ReLU()\n",
        "log_softmax = LogSoftmax()\n",
        "\n",
        "# to create a model is as simple as that\n",
        "model = MLP(layer_sizes, function, key)\n",
        "params = model.params # we need to extract parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwMdEkYm79xV"
      },
      "source": [
        "Helper functions, trainloader and other stuff..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGG55g_OmppV",
        "outputId": "d4bf38ed-77b7-4a0f-e397-6cfb7d245de0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ],
      "source": [
        "# some helper functions\n",
        "def one_hot(x, k, dtype=jnp.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
        "  \n",
        "def accuracy(params, images, targets):\n",
        "  target_class = jnp.argmax(targets, axis=1)\n",
        "  predicted_class = jnp.argmax(model(images,params), axis=1)\n",
        "  return jnp.mean(predicted_class == target_class)\n",
        "\n",
        "def loss(params, images, targets):\n",
        "  preds = model(images, params)\n",
        "  preds = log_softmax(preds)\n",
        "  return -jnp.mean(preds * targets)\n",
        "\n",
        "@jit\n",
        "def update(params, x, y):\n",
        "  grads = grad(loss)(params, x, y)\n",
        "  return [(w - step_size * dw, b - step_size * db)\n",
        "          for (w, b), (dw, db) in zip(params, grads)]\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "def numpy_collate(batch):\n",
        "  if isinstance(batch[0], np.ndarray):\n",
        "    return np.stack(batch)\n",
        "  elif isinstance(batch[0], (tuple,list)):\n",
        "    transposed = zip(*batch)\n",
        "    return [numpy_collate(samples) for samples in transposed]\n",
        "  else:\n",
        "    return np.array(batch)\n",
        "\n",
        "class NumpyLoader(data.DataLoader):\n",
        "  def __init__(self, dataset, batch_size=1,\n",
        "                shuffle=False, sampler=None,\n",
        "                batch_sampler=None, num_workers=0,\n",
        "                pin_memory=False, drop_last=False,\n",
        "                timeout=0, worker_init_fn=None):\n",
        "    super(self.__class__, self).__init__(dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        sampler=sampler,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "        collate_fn=numpy_collate,\n",
        "        pin_memory=pin_memory,\n",
        "        drop_last=drop_last,\n",
        "        timeout=timeout,\n",
        "        worker_init_fn=worker_init_fn)\n",
        "\n",
        "class FlattenAndCast(object):\n",
        "  def __call__(self, pic):\n",
        "    return np.ravel(np.array(pic, dtype=jnp.float32))\n",
        "\n",
        "# Define our dataset, using torch datasets\n",
        "mnist_dataset = MNIST('/tmp/mnist/', download=True, transform=FlattenAndCast())\n",
        "training_generator = NumpyLoader(mnist_dataset, batch_size=batch_size, num_workers=0)\n",
        "\n",
        "# Get the full train dataset (for checking accuracy while training)\n",
        "train_images = np.array(mnist_dataset.train_data).reshape(len(mnist_dataset.train_data), -1)\n",
        "train_labels = one_hot(np.array(mnist_dataset.train_labels), n_targets)\n",
        "\n",
        "# Get full test dataset\n",
        "mnist_dataset_test = MNIST('/tmp/mnist/', download=True, train=False)\n",
        "test_images = jnp.array(mnist_dataset_test.test_data.numpy().reshape(len(mnist_dataset_test.test_data), -1), dtype=jnp.float32)\n",
        "test_labels = one_hot(np.array(mnist_dataset_test.test_labels), n_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGztSd9S79xW"
      },
      "source": [
        "Here we train using backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWbp73vtq13K",
        "outputId": "9b5bd1c9-bf95-400c-e00e-31a96123f8ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 in 10.93 sec\n",
            "Training set accuracy 0.9094333648681641\n",
            "Test set accuracy 0.9138000011444092\n",
            "Epoch 1 in 10.76 sec\n",
            "Training set accuracy 0.9317333698272705\n",
            "Test set accuracy 0.9314999580383301\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb#ch0000008?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb#ch0000008?line=3'>4</a>\u001b[0m   start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb#ch0000008?line=4'>5</a>\u001b[0m   \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m training_generator:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb#ch0000008?line=5'>6</a>\u001b[0m     y \u001b[39m=\u001b[39m one_hot(y, n_targets)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb#ch0000008?line=6'>7</a>\u001b[0m     params \u001b[39m=\u001b[39m update(params, x, y)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py?line=141'>142</a>\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py?line=143'>144</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py?line=144'>145</a>\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py?line=146'>147</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/francesco/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py?line=147'>148</a>\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
            "\u001b[1;32m/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb Cell 7'\u001b[0m in \u001b[0;36mFlattenAndCast.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb#ch0000006?line=54'>55</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/francesco/Desktop/dssc/deeplearning/proj/DL-project/how_to_use.ipynb#ch0000006?line=55'>56</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mravel(np\u001b[39m.\u001b[39;49marray(pic, dtype\u001b[39m=\u001b[39;49mjnp\u001b[39m.\u001b[39;49mfloat32))\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:510\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=506'>507</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpyaccess \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=507'>508</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exif \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=509'>510</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=510'>511</a>\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=511'>512</a>\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=512'>513</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mImage categories are deprecated and will be removed in Pillow 10 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=513'>514</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(2023-07-01). Use is_animated instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=514'>515</a>\u001b[0m             \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=515'>516</a>\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    <a href='file:///usr/lib/python3/dist-packages/PIL/Image.py?line=516'>517</a>\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  for x, y in training_generator:\n",
        "    y = one_hot(y, n_targets)\n",
        "    params = update(params, x, y)\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  train_acc = accuracy(params, train_images, train_labels)\n",
        "  test_acc = accuracy(params, test_images, test_labels)\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set accuracy {}\".format(train_acc))\n",
        "  print(\"Test set accuracy {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMyZN2La79xX"
      },
      "source": [
        "## Part 1\n",
        "We first define useful parameters that we are going to use later. Note that our model is a costum model built using `Sequential` and `Linear`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3T0BVKsJ79xY"
      },
      "outputs": [],
      "source": [
        "class myModel(Module):\n",
        "    def __init__(self):\n",
        "        self.layers = Sequential([\n",
        "            Linear(28*28,512,key),\n",
        "            function,\n",
        "            Linear(512,256,key),\n",
        "            function,\n",
        "            Linear(256,10,key)\n",
        "        ])\n",
        "        self.params = self.layers.generate_parameters()\n",
        "\n",
        "    def forward(self, data, params):\n",
        "        return self.layers(data, params)\n",
        "\n",
        "\n",
        "# we define the model as simple as that\n",
        "model = myModel()\n",
        "params = model.params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaaY-qwUi1In"
      },
      "source": [
        "Let's train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kpedeNf79xY",
        "outputId": "994c375f-dd99-4e66-dcd4-9e45b302f391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 in 13.05 sec\n",
            "Training set accuracy 0.9094333648681641\n",
            "Test set accuracy 0.9138000011444092\n",
            "Epoch 1 in 11.82 sec\n",
            "Training set accuracy 0.9317333698272705\n",
            "Test set accuracy 0.9314999580383301\n",
            "Epoch 2 in 10.15 sec\n",
            "Training set accuracy 0.9435499906539917\n",
            "Test set accuracy 0.9408999681472778\n",
            "Epoch 3 in 10.45 sec\n",
            "Training set accuracy 0.9515666961669922\n",
            "Test set accuracy 0.9484999775886536\n",
            "Epoch 4 in 9.55 sec\n",
            "Training set accuracy 0.9579499959945679\n",
            "Test set accuracy 0.9536999464035034\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  for x, y in training_generator:\n",
        "    y = one_hot(y, n_targets)\n",
        "    params = update(params, x, y)\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  train_acc = accuracy(params, train_images, train_labels)\n",
        "  test_acc = accuracy(params, test_images, test_labels)\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set accuracy {}\".format(train_acc))\n",
        "  print(\"Test set accuracy {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DS8jrzYm79xZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "esempio_jax.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
